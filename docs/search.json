[{"path":"https://www.emilyzabor.com/ppseq/articles/one_sample_expansion.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"One-sample expansion cohort","text":"execute code vignette, first need install load {ppseq} package. also need {future} package parallelize code improve speed.","code":"install.packages(\"ppseq\") install.packages(\"future\") library(ppseq) library(future)"},{"path":"https://www.emilyzabor.com/ppseq/articles/one_sample_expansion.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"One-sample expansion cohort","text":"traditional phase clinical trials oncology focused identification maximum tolerated dose, typically using rule-based 3+3 design times alternative model-based design, focus now shifting interest obtaining additional safety data across range doses variety disease subtypes, characterizing preliminary efficacy. result, one-sample expansion cohorts becoming increasingly common phase clinical trials oncology, particularly context immunotherapies non-cytotoxic treatments, maximum tolerated dose may exist. expansion cohort group additional patients treated recommended phase 2 dose (RP2D), possibly several contending doses, identified dose finding portion phase study, typically used characterize toxicity /efficacy RP2D. expansion cohorts used extensively phase clinical trials oncology, often planned advance statistical properties mind, allowing sample size times expand large numbers treated patients. data patients can sometimes seem desirable, goal phase trials still focused identifying promising treatments study phase 2 beyond limiting number patients treated possibly inefficacious drugs. propose design phase expansion cohorts based sequential predictive probability monitoring allows investigator identify optimal clinical trial design within constraints traditional type error control power, futility stopping rules preserve valuable human financial resources (Zabor et al. 2022). {ppseq} package provides functions implement proposed design. vignette demonstrate use functions {ppseq} package design phase expansion cohort, context case study based study atezolizumab metastatic urothelial carcinoma.","code":""},{"path":"https://www.emilyzabor.com/ppseq/articles/one_sample_expansion.html","id":"case-study-background","dir":"Articles","previous_headings":"","what":"Case study background","title":"One-sample expansion cohort","text":"Atezolizumab anti-PD-L1 treatment originally tested phase setting basket trial across variety cancer sites harboring PD-L1 mutations. atezolizumab expansion study metastatic urothelial carcinoma primary aim evaluating safety, pharmacodynamics pharmacokinetics therefore designed meet specific criteria type error power. expansion cohort metastatic urothelial carcinoma (mUC) part original protocol design, rather added later. expansion cohort mUC ultimately enrolled total 95 participants (Petrylak et al. 2018). expansion cohorts included original protocol, including renal-cell carcinoma, non-small-cell lung cancer, melanoma, planned sample size 40. pre-planned expansion cohorts designed single interim analysis futility stop trial 0 responses seen first 14 patients enrolled. According trial protocol, futility rule associated 4.4% chance observing responses 14 patients true response rate 20% higher. protocol also states widths 90% confidence intervals sample size 40 observed response rate 30%. stated decision rule efficacy since efficacy explicit aim expansion cohorts.","code":""},{"path":"https://www.emilyzabor.com/ppseq/articles/one_sample_expansion.html","id":"re-design-of-case-study","dir":"Articles","previous_headings":"","what":"Re-design of case study","title":"One-sample expansion cohort","text":"demonstrate use functions {ppseq} re-design one-sample expansion cohort study atezolizumab mUC using sequential predictive probability monitoring. assume null, unacceptable, response rate 0.1 alternative, acceptable, response rate 0.2. plan study total 95 participants. sequential predictive probability design check futility every 5 patients enrolled. design study, need calibrate design range posterior probability thresholds predictive probability thresholds. posterior probability calculated posterior distribution based specified priors data observed far, represents probability success based data accrued far. posterior probability threshold set design stage , end trial, posterior probability exceeded pre-specified threshold, trial declared success. posterior predictive probability probability , given interim monitoring point, treatment declared efficacious end trial full enrollment reached, conditional currently observed data specified priors. Predictive probability provides intuitive monitoring framework tells investigator chances declaring treatment efficacious end trial continue enrolling maximum planned sample size, given data observed far trial. probability drops certain threshold, pre-specified design stage, trial stopped early. Predictive probability thresholds closer 0 lead less frequent stopping futility, whereas thresholds near 1 lead frequent stopping unless almost certain probability success. consider grid thresholds range possible designs select design optimal operating characteristics type error, power, sample size null alternative. example consider posterior thresholds 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, predictive thresholds 0.05, 0.1, 0.15, 0.2.","code":""},{"path":"https://www.emilyzabor.com/ppseq/articles/one_sample_expansion.html","id":"using-calibrate_thresholds-to-obtain-design-options","dir":"Articles","previous_headings":"","what":"Using calibrate_thresholds() to obtain design options","title":"One-sample expansion cohort","text":"conduct case study re-design, use calibrate_thresholds() function {ppseq} package. function written using future furrr packages, user set call future::plan appropriate operating environment simulation setup prior running function. example, used following code Unix server 192 cores, goal utilizing 40 cores since grid thresholds consider 10 posterior thresholds 4 predictive thresholds. calibrate_thresholds() function simulate nsim datasets null hypothesis nsim datasets alternative hypothesis. simulated dataset, every combination posterior predictive thresholds considered final sample size whether trial positive saved. across simulated datasets, calibrate_thresholds() return average sample size null, average sample size alternative, proportion positive trials null (.e. type error), proportion positive trials alternative (.e. power). calibrate_thresholds() randomly generates simulated datasets, want set seed running function order ensure results reproducible. inputs calibrate_thresholds() case study re-design include p_null = 0.1 null response rate, p_alt = 0.2 alternative response rate, n = seq(5, 95, 5) indicates interim looks every 5 patients total 95, direction = \"greater\" specifies interest whether alternative response rate exceeds null response rate, delta = NULL argument specifies clinically meaningful difference groups, relevant one-sample case, prior = c(0.5, 0.5) specifies hyperparameters prior beta distribution set 0.5, S = 5000 specifies 5000 posterior samples drawn calculate posterior predictive probabilities, N = 95 indicates final total sample size 95, nsim = 1000 specifies generate 1000 simulated datasets null alternative, pp_threshold vector posterior thresholds interest, ppp_threshold vector predictive thresholds interest. Note due computational time involved, object produced example code one_sample_cal_tbl available dataset {ppseq} package.","code":"set.seed(123)  future::plan(future::multicore(workers = 40))  one_sample_cal_tbl <-    calibrate_thresholds(p_null = 0.1,                         p_alt = 0.2,                         n = seq(5, 95, 5),                        N = 95,                         pp_threshold = seq(0.9, 0.99, 0.01),                        ppp_threshold = seq(0.05, 0.2, 0.05),                        direction = \"greater\",                         delta = NULL,                         prior = c(0.5, 0.5),                         S = 5000,                         nsim = 1000                        )"},{"path":"https://www.emilyzabor.com/ppseq/articles/one_sample_expansion.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"One-sample expansion cohort","text":"limit consideration designs type error 0.05 0.1, minimum power 0.7.","code":""},{"path":"https://www.emilyzabor.com/ppseq/articles/one_sample_expansion.html","id":"print","dir":"Articles","previous_headings":"Results","what":"print()","title":"One-sample expansion cohort","text":"pass results calibrate_thresholds() print() get back table resulting design options satisfy desired range type error, specified vector minimum maximum passed type1_range argument, minimal power, specified numeric value 0 1 passed argument minimum_power. find 9 40 considered combinations posterior predictive thresholds result design within acceptable range type error minimal power. column labeled prop_pos_null contains proportion positive trials null, represents type error rate, column labeled prop_pos_alt contains proportion positive trials alternative, represents power. column labeled mean_n1_null contains average sample size null whereas column labeled mean_n1_alt contains average sample size alternative.","code":"print(one_sample_cal_tbl,        type1_range = c(0.05, 0.1),        minimum_power = 0.7)"},{"path":"https://www.emilyzabor.com/ppseq/articles/one_sample_expansion.html","id":"optimize_design","dir":"Articles","previous_headings":"Results","what":"optimize_design()","title":"One-sample expansion cohort","text":"Finally, can pass results call calibrate_thresholds() optimize_design() function list optimal design respect type error power, termed “optimal accuracy” design, optimal design respect average sample sizes null alternative, termed “optimal efficiency” design, within specified range acceptable type error minimum power. optimal accuracy design one posterior threshold 0.92 predictive threshold 0.05. type error 0.081, power 0.874, average sample size null 51, average sample size alternative 90. optimal efficiency design one posterior threshold 0.92 predictive threshold 0.1. type error 0.073, power 0.793, average sample size null 39, average sample size alternative 82. comparison, original design atezolizumab expansion cohort mUC, single look futility first 14 patients, type error 0.005, power 0.528, average sample size null 76, average sample size alternative 92. case study, find either optimal accuracy optimal efficiency sequential predictive probability design superior performance original design atezolizumab expansion cohort mUC respect type error power, average sample size null. case may choose use optimal efficiency design, desirable trait small average sample size null just 39 patients, still maintaining reasonable type error 0.073 power 0.793. design allow us stop early treatment inefficacious, thus preserving valuable financial resources use studying promising treatments preventing human subjects continuing ineffective treatment.","code":"optimize_design(one_sample_cal_tbl,                  type1_range = c(0.05, 0.1),                  minimum_power = 0.7) #> $`Optimal accuracy design:` #> # A tibble: 1 × 6 #>   pp_threshold ppp_threshold `Type I error` Power `Average N under the null` #>          <dbl>         <dbl>          <dbl> <dbl>                      <dbl> #> 1         0.92          0.05          0.081 0.874                       50.6 #>   `Average N under the alternative` #>                               <dbl> #> 1                              89.9 #>  #> $`Optimal efficiency design:` #> # A tibble: 1 × 6 #>   pp_threshold ppp_threshold `Type I error` Power `Average N under the null` #>          <dbl>         <dbl>          <dbl> <dbl>                      <dbl> #> 1         0.92           0.1          0.073 0.793                       38.8 #>   `Average N under the alternative` #>                               <dbl> #> 1                              81.8"},{"path":"https://www.emilyzabor.com/ppseq/articles/one_sample_expansion.html","id":"calc_decision_rules","dir":"Articles","previous_headings":"Results","what":"calc_decision_rules()","title":"One-sample expansion cohort","text":"selected design interest, need obtain decision rules futility monitoring time easy implementation trial. can passing parameters selected design calc_decision_rules(). input parameters n, direction, p0, delta, prior, S, N calibrate_thresholds(). input parameter theta = 0.92 specifies interested posterior probability threshold 0.92 input parameter ppp = 0.1 specifies interested predictive probability threshold 0.1, determined optimal efficiency design . Note due computational time involved, object produced example code one_sample_decision_tbl available dataset {ppseq} package. results table, n indicates number enrolled patients look futility r indicates number response stop trial given interim look number observed responses <=r, end trial treatment considered promising number observed responses >r. case see first interim futility look just 5 patients, stop trial. first 10 patients stop trial 0 responses, . end trial 95 patients accrued, declare treatment promising study >=14 responses.","code":"set.seed(123)  one_sample_decision_tbl <-    calc_decision_rules(     n = seq(5, 95, 5),      N = 95,      theta = 0.92,      ppp = 0.1,      p0 = 0.1,      direction = \"greater\",      delta = NULL,      prior = c(0.5, 0.5),      S = 5000     ) one_sample_decision_tbl"},{"path":"https://www.emilyzabor.com/ppseq/articles/one_sample_expansion.html","id":"plot","dir":"Articles","previous_headings":"Results","what":"plot()","title":"One-sample expansion cohort","text":"Passing results calibrate_thresholds() plot() returns two plots, one type error power, one average sample size null average sample size alternative. arguments type1_range power used way print() function. argument plotly defaults FALSE, results pair side--side ggplots returned. set TRUE, two individual interactive plotly plots returned, demonstrated . Note points tied based optimization criteria, point highest posterior predictive threshold selected plotting. diamond-shaped point represents optimal design based criteria, discussed detail . Using plotly = TRUE option plot() can hover point see x-axis y-axis values, along distance top left corner plot, posterior predictive thresholds associated point. Passing results calc_decision_rules() plot() returns one plot. x-axis indicates sample size interim analysis, y-axis indicates number possible responses interim analysis. color denotes whether trial proceed (green) stop (red). Hovering box indicate combination sample size responses decision time. Note plot useful two-sample case, number responses control group number responses experimental group must considered simultaneously, resulting grid plots interim analysis point.","code":"plot(one_sample_cal_tbl,       type1_range = c(0.05, 0.1),       minimum_power = 0.7,      plotly = TRUE) plot(one_sample_decision_tbl)"},{"path":[]},{"path":"https://www.emilyzabor.com/ppseq/articles/two_sample_randomized.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Two-sample randomized trial","text":"execute code vignette, first need install load {ppseq} package. also need {future} package parallelize code improve speed.","code":"install.packages(\"ppseq\") install.packages(\"future\") library(ppseq) library(future)"},{"path":"https://www.emilyzabor.com/ppseq/articles/two_sample_randomized.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Two-sample randomized trial","text":"Efforts develop biomarker-targeted anti-cancer therapies progressed rapidly recent years. aim expediting regulatory reviews promising therapies, increasing number targeted cancer therapies granted accelerated approval basis evidence acquired single-arm phase II clinical trials. historical control rates used design evaluate emerging targeted therapies single-arm trials often arise population averages, lacking specificity biomarker-targeted subpopulation interest. Thus, historical trial results inherently limited inferring potential “comparative efficacy” novel targeted therapies. Randomization may best option setting, question given increasingly large sample sizes used phase II trials. propose design two-arm randomized phase II trials based sequential predictive probability monitoring allows investigator identify optimal clinical trial design within constraints traditional type error power, futility stopping rules preserve valuable human financial resources (cite two-sample paper ’s available).","code":""},{"path":"https://www.emilyzabor.com/ppseq/articles/two_sample_randomized.html","id":"case-study-background","dir":"Articles","previous_headings":"","what":"Case study background","title":"Two-sample randomized trial","text":"Atezolizumab programmed death-ligand 1 (PD-L1) blocking monoclonal antibody given accelerated approval U.S. Food Drug Administration May 2016 treatment patients locally advanced metastatic urothelial carcinoma disease progression following platinum-containing chemotherapy. approval based results single-arm phase II study 310 patients (Rosenberg et al. 2016). phase II study used hierarchical fixed-sequence testing procedure test increasingly broad subgroups patients based PD-L1 status, found overall response rates 26% (95% CI: 18-36), 18% (95% CI: 13-24), 15% (95% CI 11-19) patients ≥5% PD-L1-positive immune cells (IC2/3 subgroup), patients ≥1% PD-L1-positive immune cells (IC1/2/3 subgroup), patients, respectively (Rosenberg et al. 2016). three rates exceeded historical control rate 10%. , March 2021, approval indication voluntarily withdrawn sponsor following negative results randomized phase III study (Powles et al. 2018). phase III study, 931 patients randomly assigned receive atezolizumab chemotherapy 1:1 ratio, hierarchical fixed-sequence testing procedure phase II study used. phase III study found overall survival differ significantly atezolizumab chemotherapy groups IC2/3 subgroup (median survival 11.1 months [95% CI: 8.6-15.5] versus 10.6 months [95% CI: 8.4-12.2]), testing conducted primary endpoint. analyses revealed response rates atezolizumab comparable seen phase II study, response rates chemotherapy much higher historical control rate 10%. overall response rates chemotherapy 21.6% (95% CI: 14.5-30.2), 14.7% (95% CI: 10.9-19.2), 13.4% (95% CI: 10.5-16.9) IC2/3 subgroup, IC1/2/3 subgroup, patients, respectively. overall response rates atezolizumab 23% (95% CI: 15.6-31.9), 14.1% (95% CI: 10.4-18.5), 13.4% (95% CI: 10.5-16.9) IC2/3 subgroup, IC1/2/3 subgroup, patients, respectively. results indicate PD-L1 status predictive biomarker standard care chemotherapies comprised control arm well atezolizumab patient population.","code":""},{"path":"https://www.emilyzabor.com/ppseq/articles/two_sample_randomized.html","id":"re-design-of-case-study","dir":"Articles","previous_headings":"","what":"Re-design of case study","title":"Two-sample randomized trial","text":"demonstrate use functions {ppseq} re-design phase II trial atezolizumab using two-arm randomized design sequential predictive probability monitoring. focus main biomarker subgroup interest, IC2/3 subgroup. design study null response rate 0.1 arms, alternative response rate 0.25 atezolizumab arm. plan study 100 participants, assuming total sample size available similar 310 used actual single-arm phase II trial, third patient population fall desired biomarker subgroup. check futility every 10 patients enrolled arm. design study, need calibrate design range posterior probability thresholds predictive probability thresholds. posterior probability calculated posterior distribution based specified priors data observed far, represents probability success based data accrued far. posterior probability threshold set design stage , end trial, posterior probability exceeded pre-specified threshold, trial declared success. posterior predictive probability probability , given interim monitoring point, treatment declared efficacious end trial full enrollment reached, conditional currently observed data specified priors. Predictive probability provides intuitive monitoring framework tells investigator chances declaring treatment efficacious end trial continue enrolling maximum planned sample size, given data observed far trial. probability drops certain threshold, pre-specified design stage, trial stopped early. Predictive probability thresholds closer 0 lead less frequent stopping futility, whereas thresholds near 1 lead frequent stopping unless almost certain probability success. consider grid thresholds range possible designs select design optimal operating characteristics type error, power, sample size null alternative. example consider posterior thresholds 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, predictive thresholds 0.05, 0.1, 0.15, 0.2.","code":""},{"path":"https://www.emilyzabor.com/ppseq/articles/two_sample_randomized.html","id":"using-calibrate_thresholds-to-obtain-design-options","dir":"Articles","previous_headings":"","what":"Using calibrate_thresholds() to obtain design options","title":"Two-sample randomized trial","text":"conduct case study re-design, use calibrate_thresholds() function {ppseq} package. function written using future furrr packages, user set call future::plan appropriate operating environment simulation setup prior running function. example, used following code Unix server 192 cores, goal utilizing 40 cores since grid thresholds consider 10 posterior thresholds 4 predictive thresholds. calibrate_thresholds() function simulate nsim datasets null hypothesis nsim datasets alternative hypothesis. simulated dataset, every combination posterior predictive thresholds considered final sample size whether trial positive saved. across simulated datasets, calibrate_thresholds() return average sample size null, average sample size alternative, proportion positive trials null (.e. type error), proportion positive trials alternative (.e. power). calibrate_thresholds() randomly generates simulated datasets, want set seed running function order ensure results reproducible. inputs calibrate_thresholds() case study re-design include p_null = c(0.1, 0.1) null response rate, p_alt = c(0.1, 0.25) alternative response rate, n = cbind(seq(10, 50, 10), seq(10, 50, 10)) indicates interim looks every 10 patients total 50 arm, N = c(50, 50) indicates final total sample size 50 arm, direction = \"greater\" specifies interest whether response rate experimental arm exceeds response rate control arm, delta = 0 default clinically meaningful difference two-sample case, prior = c(0.5, 0.5) specifies hyperparameters prior beta distribution set 0.5, S = 5000 specifies 5000 posterior samples drawn calculate posterior predictive probabilities, nsim = 1000 specifies generate 1000 simulated datasets null alternative. pp_threshold vector posterior thresholds interest ppp_threshold vector predictive thresholds interest. Note due computational time involved, object produced example code two_sample_cal_tbl available dataset {ppseq} package.","code":"set.seed(123)  future::plan(future::multicore(workers = 40))  two_sample_cal_tbl <-    calibrate_thresholds(p_null = c(0.1, 0.1),                         p_alt = c(0.1, 0.25),                         n = cbind(seq(10, 50, 10), seq(10, 50, 10)),                        N = c(50, 50),                         pp_threshold = seq(0.9, 0.99, 0.01),                        ppp_threshold = seq(0.05, 0.2, 0.05),                        direction = \"greater\",                         delta = 0,                         prior = c(0.5, 0.5),                         S = 5000,                         nsim = 1000                        )"},{"path":"https://www.emilyzabor.com/ppseq/articles/two_sample_randomized.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"Two-sample randomized trial","text":"limit consideration designs type error 0.05 0.1, minimum power 0.7.","code":""},{"path":"https://www.emilyzabor.com/ppseq/articles/two_sample_randomized.html","id":"print","dir":"Articles","previous_headings":"Results","what":"print()","title":"Two-sample randomized trial","text":"pass results calibrate_thresholds() print() get back table resulting design options satisfy desired range type error, specified vector minimum maximum passed type1_range argument, minimal power, specified numeric value 0 1 passed argument minimum_power. find 4 40 considered combinations posterior predictive thresholds result design within acceptable range type error minimal power. column labeled prop_pos_null contains proportion positive trials null, represents type error rate, column labeled prop_pos_alt contains proportion positive trials alternative, represents power. column labeled mean_n1_null contains average sample size null whereas column labeled mean_n1_alt contains average sample size alternative.","code":"print(two_sample_cal_tbl,        type1_range = c(0.05, 0.1),        minimum_power = 0.7)"},{"path":"https://www.emilyzabor.com/ppseq/articles/two_sample_randomized.html","id":"optimize_design","dir":"Articles","previous_headings":"Results","what":"optimize_design()","title":"Two-sample randomized trial","text":"Finally, can pass results call calibrate_thresholds() optimize_design() function list optimal design respect type error power, termed “optimal accuracy” design, optimal design respect average sample sizes null alternative, termed “optimal efficiency” design, within specified range acceptable type error minimum power. optimal accuracy design one posterior threshold 0.9 predictive threshold 0.05. type error 0.083, power 0.738, average sample size null 30 per arm, average sample size alternative 46 per arm. optimal efficiency design one posterior threshold 0.92 predictive threshold 0.05. type error 0.07, power 0.7, average sample size null 29 per arm, average sample size alternative 46 per arm. find either optimal accuracy optimal efficiency sequential predictive probability design reasonable type error power detect effect interest, results much lower average total sample size null alternative 310 actually used phase II study atezolizumab. Additionally, randomized design allow direct estimation response rate experimental treatment standard care treatment biomarker subgroup interest, thus avoiding issues historical control rates arose original atezolizumab study. design prevent problem targeted biomarker prognostic rather predictive, uses fewer patients avoids continuation phase III unwarranted.","code":"optimize_design(two_sample_cal_tbl,                  type1_range = c(0.05, 0.1),                  minimum_power = 0.7) #> $`Optimal accuracy design:` #> # A tibble: 1 × 6 #>   pp_threshold ppp_threshold `Type I error` Power `Average N under the null` #>          <dbl>         <dbl>          <dbl> <dbl>                      <dbl> #> 1          0.9          0.05          0.083 0.738                       29.9 #>   `Average N under the alternative` #>                               <dbl> #> 1                              46.2 #>  #> $`Optimal efficiency design:` #> # A tibble: 1 × 6 #>   pp_threshold ppp_threshold `Type I error` Power `Average N under the null` #>          <dbl>         <dbl>          <dbl> <dbl>                      <dbl> #> 1         0.92          0.05           0.07 0.701                       28.6 #>   `Average N under the alternative` #>                               <dbl> #> 1                              45.5"},{"path":"https://www.emilyzabor.com/ppseq/articles/two_sample_randomized.html","id":"calc_decision_rules","dir":"Articles","previous_headings":"Results","what":"calc_decision_rules()","title":"Two-sample randomized trial","text":"selected design interest, need obtain decision rules futility monitoring time easy implementation trial. can passing parameters selected design calc_decision_rules(). input parameters n, direction, p0, delta, prior, S, N calibrate_thresholds(). input parameter theta = 0.92 specifies interested posterior probability threshold 0.92 input parameter ppp = 0.05 specifies interested predictive probability threshold 0.05, determined optimal efficiency design . Note due computational time involved, object produced example code two_sample_decision_tbl available dataset {ppseq} package. first 11 rows resulting table, contains possible combinations number responses control experimental arms stop trial interim look. results table, n0 indicates number enrolled patients control arm n1 indicates number enrolled patients treatment arm look futility; r0 indicates number responses control arm r1 indicates number responses treatment arm stop trial given interim look number observed responses <=r1 given fixed value r0. end trial treatment considered promising number observed responses >r1 given r0. example, case see 4 responses control arm first 10 control arm patients, stop trial 2 fewer responses experimental arm first 10 experimental arm patients.","code":"set.seed(123)  two_sample_decision_tbl <-    calc_decision_rules(     n = cbind(seq(10, 50, 10), seq(10, 50, 10)),     N = c(50, 50),     theta = 0.92,      ppp = 0.05,      p0 = NULL,      direction = \"greater\",      delta = 0,      prior = c(0.5, 0.5),      S = 5000     ) two_sample_decision_tbl"},{"path":"https://www.emilyzabor.com/ppseq/articles/two_sample_randomized.html","id":"plot","dir":"Articles","previous_headings":"Results","what":"plot()","title":"Two-sample randomized trial","text":"Passing results calibrate_thresholds() plot() returns two plots, one type error power, one average sample size null average sample size alternative. arguments type1_range power used way print() function. argument plotly defaults FALSE, results pair side--side plots produced {ggplot2} package. set TRUE, two individual interactive plots produced {plotly} package returned, demonstrated . Note points tied based optimization criteria, point highest posterior predictive threshold selected plotting. diamond-shaped point represents optimal design based criteria, discussed detail . Using plotly = TRUE option plot() can hover point see x-axis y-axis values, along distance top left corner plot, posterior predictive thresholds associated point, average sample sizes null alternative arm. Passing results calc_decision_rules() plot() returns faceted plot according interim look. One plot, x-axis indicates number responses control arm y-axis indicates number responses experimental arm. color denotes whether trial proceed (green) stop (red). Hovering box indicate combination sample size responses decision time.","code":"plot(two_sample_cal_tbl,       type1_range = c(0.05, 0.1),       minimum_power = 0.7,      plotly = TRUE) plot(two_sample_decision_tbl)"},{"path":[]},{"path":"https://www.emilyzabor.com/ppseq/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Emily C. Zabor. Author, maintainer. Brian P. Hobbs. Author. Michael J. Kane. Author.","code":""},{"path":"https://www.emilyzabor.com/ppseq/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Zabor E, Hobbs B, Kane M (2023). ppseq: Design Clinical Trials using Sequential Predictive Probability Monitoring. https://github.com/zabore/ppseq, https://www.emilyzabor.com/ppseq/.","code":"@Manual{,   title = {ppseq: Design Clinical Trials using Sequential Predictive Probability Monitoring},   author = {Emily C. Zabor and Brian P. Hobbs and Michael J. Kane},   year = {2023},   note = {https://github.com/zabore/ppseq, https://www.emilyzabor.com/ppseq/}, }"},{"path":"https://www.emilyzabor.com/ppseq/index.html","id":"ppseq","dir":"","previous_headings":"","what":"ppseq","title":"Design Clinical Trials using Sequential Predictive Probability Monitoring","text":"{ppseq} package provides functions design clinical trials using Bayesian sequential predictive probability monitoring. Functionality available design one-arm two-arm trials searching grid combinations posterior predictive thresholds identifying optimal design according two criteria: accuracy efficiency. Interactive plotting allows easy comparison various design options easy trial implementation decision rule plots.","code":""},{"path":"https://www.emilyzabor.com/ppseq/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Design Clinical Trials using Sequential Predictive Probability Monitoring","text":"can install production version ppseq CRAN : can install development version ppseq GitHub :","code":"install.packages(\"ppseq\") remotes::install_github(\"zabore/ppseq\")"},{"path":"https://www.emilyzabor.com/ppseq/index.html","id":"basic-usage","dir":"","previous_headings":"","what":"Basic usage","title":"Design Clinical Trials using Sequential Predictive Probability Monitoring","text":"primary function search grid combinations posterior predictive thresholds certain trial design calibrate_thresholds(). function computationally intensive varying degrees depending number looks number threshold combinations, best run server /parallelization. resulting design options can compared interactively compared passing results plot() option plotly = TRUE. Static versions plots also available using default option plotly = FALSE, produces ggplot results. Plot output can optionally filtered desired range type 1 error minimum power. default plots design options. results can also viewed tabular form passing results print() filtering options desired range type 1 error minimum power.  optimal accuracy optimal efficiency designs can obtained passing results optimize_design() function, filtering applied desired range type 1 error minimum power.  selecting design, can obtain set decision rules implement trial, calculations needed course trial. calc_decision_rules() function generate decision rules stop continue interim look trial. results can displayed interactive graphics passing results plot() default option plotly = TRUE. static ggplot versions created option plotly = FALSE demonstration purposes. Tabular results can obtained passing results print().  See vignettes one-sample two-sample cases additional details available features options.","code":"library(ppseq) set.seed(12345)  calthresh <-   calibrate_thresholds(     p_null = c(0.2, 0.2),     p_alt = c(0.2, 0.5),     n = cbind(seq(10, 50, 10), seq(10, 50, 10)),     N = c(50, 50),     pp_threshold = seq(0.9, 0.95, 0.01),     ppp_threshold = seq(0.05, 0.2, 0.05),     delta = 0     ) plot(calthresh) optimize_design(calthresh, type1_range = c(0.025, 0.05), minimum_power = 0.8) set.seed(123456)  opteffrules <-    calc_decision_rules(     n = cbind(seq(10, 50, 10), seq(10, 50, 10)),     N = c(50, 50),     theta = 0.94,     ppp = 0.2,     p0 = NULL,      delta = 0   ) plot(opteffrules, plotly = FALSE)"},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_decision_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a decision rule table for interim monitoring of a pre-specified\r\ndesign — calc_decision_rules","title":"Calculate a decision rule table for interim monitoring of a pre-specified\r\ndesign — calc_decision_rules","text":"function take posterior predictive thresholds pre-specified design given null response rate fixed interim looks total sample size, return decision rules interim analysis end trial. Intended use selecting optimal design using functions calibrate_thresholds optimize_design.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_decision_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a decision rule table for interim monitoring of a pre-specified\r\ndesign — calc_decision_rules","text":"","code":"calc_decision_rules(   n,   N,   theta,   ppp,   p0,   direction = \"greater\",   delta = NULL,   prior = c(0.5, 0.5),   S = 5000 )"},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_decision_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a decision rule table for interim monitoring of a pre-specified\r\ndesign — calc_decision_rules","text":"n matrix containing total number patients accrued far interim look standard care (column 1) experimental (column 2) arms two-sample case; vector sample size accrued far interim look one-sample case. last value equal total sample size end trial. single look done end trial, can vector specifying total sample size c(N0, N1) two-sample case integer specifying total sample size N one-sample case N total planned sample size end trial, c(N0, N1) two-sample case; integer total planned sample size end trial N one-sample case theta target posterior probability. e.g. Efficacy decision P(p1 > p0) > theta two-sample case greater direction. ppp target predictive probability. e.g. Stop trial predictive probability falls target. p0 target value compare one-sample case. Set NULL two-sample case. direction \"greater\" (default) interest P(p1 > p0) \"less\" interest P(p1 < p0) two-sample case. one-sample case, \"greater\" interest P(p > p0) \"less\" interest P(p < p0). delta clinically meaningful difference groups. Typically 0 two-sample case. NULL one-sample case (default). prior hyperparameters prior beta distribution. Beta(0.5, 0.5) default S number samples, default 5000","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_decision_rules.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a decision rule table for interim monitoring of a pre-specified\r\ndesign — calc_decision_rules","text":"one-sample case, returns tibble n look, r look, ppp, associated posterior predictive probability. Stop trial look number observed responses <=r. end trial, treatment considered promising number observed responses >r. two-sample case, returns tibble n0 n1, number enrolled subjects control experimental arms look, respectively, r0 r1, number possible responses control experimental arms look, respectively, ppp, associated posterior predictive probability. given value r0, stop trial number observed responses experimental arm <=r1. end trial, treatment considered promising number observed responses experimental arm >r1 given r0. NA value either table represents interim look number responses lead stopping trial.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_decision_rules.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a decision rule table for interim monitoring of a pre-specified\r\ndesign — calc_decision_rules","text":"","code":"set.seed(123)  # One-sample case calc_decision_rules(   n = seq(5, 25, 5),    N = 25,    theta = 0.86,    ppp = 0.2,    p0 = 0.1,    S = 50   ) #> # A tibble: 5 × 3 #>       n     r   ppp #>   <dbl> <int> <dbl> #> 1     5     0  0.18 #> 2    10     0  0.04 #> 3    15     1  0.08 #> 4    20     2  0.1  #> 5    25     3  0     # Two-sample case calc_decision_rules(   n = cbind(seq(5, 25, 5), seq(5, 25, 5)),    N = c(25, 25),   theta = 0.86,    ppp = 0.2,    p0 = NULL,    direction = \"greater\",    delta = 0,    S = 50   ) #> # A tibble: 80 × 5 #>       n0    n1    r0    r1   ppp #>    <dbl> <dbl> <int> <int> <dbl> #>  1     5     5     0     0  0.2  #>  2     5     5     1     0  0.06 #>  3     5     5     2     1  0.04 #>  4     5     5     3     2  0.04 #>  5     5     5     4     3  0.06 #>  6     5     5     5     5  0.2  #>  7    10    10     0     0  0.16 #>  8    10    10     1     1  0.18 #>  9    10    10     2     2  0.06 #> 10    10    10     3     3  0.16 #> # … with 70 more rows"},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_next.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate response probability for the next patient — calc_next","title":"Calculate response probability for the next patient — calc_next","text":"function meant used context clinical trial binary endpoint. two-sample case, total number events standard--care arm y0 total number events experimental arm y1. function samples posterior beta distribution based data prior beta hyperparameters, returns empiric mean bootstrap confidence interval next patient. empiric mean represents probability binary outcome occurring next patient. one-sample case also available.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_next.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate response probability for the next patient — calc_next","text":"","code":"calc_next(y, n, prior = c(0.5, 0.5), S = 5000, interval = 0.95)"},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_next.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate response probability for the next patient — calc_next","text":"y number events observed far. Vector length two c(y0, y1) two-sample case; integer y one-sample case. n sample size observed far. Vector length two c(n0, n1) two-sample case; integer n one-sample case. prior vector length two containing hyperparameters prior beta distribution. c(0.5, 0.5) default, Beta(0.5, 0.5) distribution. S number samples, default 5000 interval value 0 1 indicating width desired interval, default 0.95","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_next.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate response probability for the next patient — calc_next","text":"Returns tibble group indicator (two-sample case ), empiric mean, bootstrap confidence interval, specified width confidence interval.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_next.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate response probability for the next patient — calc_next","text":"","code":"set.seed(123)  # One-sample case calc_next(   y = 27,    n = 100,   S = 100   ) #> # A tibble: 1 × 4 #>   Probability `Lower CI` `Upper CI`    CI #>         <dbl>      <dbl>      <dbl> <dbl> #> 1        0.31       0.19       0.36  0.95  # Two-sample case calc_next(   y = c(14, 23),    n = c(100, 100),   S = 100   ) #> # A tibble: 2 × 5 #>   Group Probability `Lower CI` `Upper CI`    CI #>   <dbl>       <dbl>      <dbl>      <dbl> <dbl> #> 1     0        0.14       0.08       0.22  0.95 #> 2     1        0.22       0.15       0.31  0.95"},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a single posterior probability — calc_posterior","title":"Calculate a single posterior probability — calc_posterior","text":"function meant used context clinical trial binary endpoint. two-sample case, total number events standard--care arm y0 total number events experimental arm y1. function samples posterior beta distribution based data prior beta hyperparameters, returns posterior probability p1 greater (less ) p0 given data. one-sample case also available, target p0 must specified function returns posterior probability p greater (less ) p0 given data.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a single posterior probability — calc_posterior","text":"","code":"calc_posterior(   y,   n,   p0,   direction = \"greater\",   delta = NULL,   prior = c(0.5, 0.5),   S = 5000 )"},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a single posterior probability — calc_posterior","text":"y number events observed far. Vector length two c(y0, y1) two-sample case; integer y one-sample case. n sample size observed far. Vector length two c(n0, n1) two-sample case; integer n one-sample case. p0 target value compare one-sample case. Set NULL two-sample case. direction \"greater\" (default) interest P(p1 > p0) two-sample case P(p > p0) one-sample case; \"less\" interest P(p1 < p0) two-sample case P(p < p0) one-sample case. delta clinically meaningful difference groups. Typically 0 two-sample case. NULL one-sample case (default). prior vector length two containing hyperparameters prior beta distribution. c(0.5, 0.5) default, Beta(0.5, 0.5) distribution. S number samples, default 5000","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a single posterior probability — calc_posterior","text":"Returns numeric posterior probability","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a single posterior probability — calc_posterior","text":"","code":"set.seed(123)  # One-sample case calc_posterior(   y = 27,    n = 100,    p0 = 0.2   ) #> [1] 0.9558  # Two-sample case calc_posterior(   y = c(14, 23),    n = c(100, 100),    p0 = NULL,    delta = 0   ) #> [1] 0.9508"},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_predictive.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a single posterior predictive probability — calc_predictive","title":"Calculate a single posterior predictive probability — calc_predictive","text":"function meant used context clinical trial binary endpoint. goal calculate posterior predictive probability success end trial, given data available interim analysis. two-sample case number events observed interim analysis, sample size interim analysis, total planned sample size denoted y0, n0, N0 standard--care arm y1, n1, N1 experimental arm. one-sample case, number events observed interim analysis, sample size interim analysis, total planned sample size denoted y, n, N.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_predictive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a single posterior predictive probability — calc_predictive","text":"","code":"calc_predictive(   y,   n,   p0,   N,   direction = \"greater\",   delta = NULL,   prior = c(0.5, 0.5),   S = 5000,   theta = 0.95 )"},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_predictive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a single posterior predictive probability — calc_predictive","text":"y number events observed far. Vector length two c(y0, y1) two-sample case; integer y one-sample case. n sample size observed far. Vector length two c(n0, n1) two-sample case; integer n one-sample case. p0 target value compare one-sample case. Set NULL two-sample case. N total planned sample size end trial. Vector length two c(N0, N1) two-sample case; integer N one-sample case. direction \"greater\" (default) interest P(p1 > p0) two-sample case P(p > p0) one-sample case; \"less\" interest P(p1 < p0) two-sample case P(p < p0) one-sample case. delta clinically meaningful difference groups. Typically 0 two-sample case. NULL one-sample case (default). prior vector length two containing hyperparameters prior beta distribution. c(0.5, 0.5) default, Beta(0.5, 0.5) distribution. S number samples, default 5000 theta target posterior probability. e.g. Efficacy decision P(p1 > p0) > theta two-sample case greater direction. Default 0.95.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_predictive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a single posterior predictive probability — calc_predictive","text":"Returns numeric posterior predictive probability","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calc_predictive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a single posterior predictive probability — calc_predictive","text":"","code":"set.seed(123)  # Setting S = 100 for speed, in practice you would want a much larger sample  # One-sample case  calc_predictive(   y = 14,    n = 50,    p0 = 0.2,    N = 100,    S = 100   ) #> [1] 0.55  # Two-sample case  calc_predictive(   y = c(7, 12),    n = c(50, 50),    p0 = NULL,    N = c(100, 100),   delta = 0,   S = 100   ) #> [1] 0.57"},{"path":"https://www.emilyzabor.com/ppseq/reference/calibrate_posterior_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrate the posterior probability threshold — calibrate_posterior_threshold","title":"Calibrate the posterior probability threshold — calibrate_posterior_threshold","text":"function meant used context clinical trial binary endpoint. vector possible posterior decision thresholds, function simulates many trials calculates average number times posterior probability exceeds given threshold. null case, result type error given threshold. alternative case, result power given threshold.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calibrate_posterior_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrate the posterior probability threshold — calibrate_posterior_threshold","text":"","code":"calibrate_posterior_threshold(   p,   N,   p0,   direction = \"greater\",   delta = NULL,   prior = c(0.5, 0.5),   S = 5000,   theta )"},{"path":"https://www.emilyzabor.com/ppseq/reference/calibrate_posterior_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrate the posterior probability threshold — calibrate_posterior_threshold","text":"p vector length two containing probability event standard care experimental arm c(p0, p1) two-sample case; integer event probability one-sample case N vector length two containing total sample size c(N0, N1) two-sample case; integer sample size far N one-sample case p0 target value compare one-sample case. Set NULL two-sample case. direction \"greater\" (default) interest p(p1 > p0) \"less\" interest p(p1 < p0) two-sample case. one-sample case, \"greater\" interest p(p > p0) \"less\" interest p(p < p0). delta clinically meaningful difference groups. Typically 0 two-sample case. NULL one-sample case (default). prior hyperparameters prior beta distribution. Beta(0.5, 0.5) default S number samples drawn posterior, number simulated trials. Default 5000 theta target posterior probability thresholds consider. Integer vector.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calibrate_posterior_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrate the posterior probability threshold — calibrate_posterior_threshold","text":"Returns tibble posterior probability threshold(s) associated proportion positive trials.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calibrate_posterior_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrate the posterior probability threshold — calibrate_posterior_threshold","text":"","code":"set.seed(123)  # Setting S = 100 for speed, in practice you would want a much larger sample  # One-sample case calibrate_posterior_threshold(   p = 0.1,   N = 50,   p0 = 0.1,   S = 100,   theta = c(0.9, 0.95)   ) #> # A tibble: 2 × 2 #>   pp_threshold prop_pos #>          <dbl>    <dbl> #> 1         0.9      0.14 #> 2         0.95     0.02  # Two-sample case calibrate_posterior_threshold(   p = c(0.1, 0.1),   N = c(50, 50),   p0 = NULL,   delta = 0,   S = 100,   theta = c(0.9, 0.95)   ) #> # A tibble: 2 × 2 #>   pp_threshold prop_pos #>          <dbl>    <dbl> #> 1         0.9      0.1  #> 2         0.95     0.04"},{"path":"https://www.emilyzabor.com/ppseq/reference/calibrate_thresholds.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrate according to posterior probability threshold and predictive\r\nprobability threshold with interim futility monitoring — calibrate_thresholds","title":"Calibrate according to posterior probability threshold and predictive\r\nprobability threshold with interim futility monitoring — calibrate_thresholds","text":"function meant used context clinical trial binary endpoint. every combination provided posterior thresholds predictive thresholds, function simulates many trials calculates average number times trial positive. null case, type error given thresholds. alternative case, power given thresholds.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calibrate_thresholds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrate according to posterior probability threshold and predictive\r\nprobability threshold with interim futility monitoring — calibrate_thresholds","text":"","code":"calibrate_thresholds(   p_null,   p_alt,   n,   N,   pp_threshold,   ppp_threshold,   direction = \"greater\",   delta = NULL,   monitoring = \"futility\",   prior = c(0.5, 0.5),   S = 5000,   nsim = 1000 )"},{"path":"https://www.emilyzabor.com/ppseq/reference/calibrate_thresholds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrate according to posterior probability threshold and predictive\r\nprobability threshold with interim futility monitoring — calibrate_thresholds","text":"p_null vector length two containing probability event standard care experimental arm c(p0, p1) two-sample case null scenario; integer event probability one-sample case p_alt vector length two containing probability event standard care experimental arm c(p0, p1) two-sample case alternative scenario; integer event probability one-sample case n matrix containing total number patients accrued far interim look standard care (column 1) experimental (column 2) arms two-sample case; vector sample size accrued far interim look one-sample case. last value equal total sample size end trial. single look done end trial, can vector specifying total sample size c(N0, N1) two-sample case integer specifying total sample size N one-sample case N total planned sample size end trial, c(N0, N1) two-sample case; integer total planned sample size end trial N one-sample case pp_threshold posterior probability threshold interest ppp_threshold posterior predictive probability threshold interest futility monitoring direction \"greater\" (default) interest p(p1 > p0) \"less\" interest p(p1 < p0) two-sample case. one-sample case, \"greater\" interest p(p > p0) \"less\" interest p(p < p0). delta clinically meaningful difference groups. Typically 0 two-sample case. NULL one-sample case (default). monitoring type interim monitoring performed. One \"futility\" \"efficacy\". Default \"futility\". prior hyperparameters prior beta distribution. Beta(0.5, 0.5) default S number samples drawn posterior. Default 5000 nsim Number simulated trial datasets.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calibrate_thresholds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrate according to posterior probability threshold and predictive\r\nprobability threshold with interim futility monitoring — calibrate_thresholds","text":"list containing tibble 'res_summary' containing posterior probability threshold (pp_threshold), predictive probability threshold (ppp_threshold), mean sample size null (mean_n0_null mean_n1_null two-sample case; mean_n1_null one-sample case), proportion positive trials null (prop_pos_null), proportion trials stopped early null (prop_stopped_null), mean sample size alternative (mean_n0_alt mean_n1_alt two-sample case; mean_n1_alt one-sample case), proportion positive trials alternative (prop_pos_alt), proportion trials stopped early alternative (prop_stopped_alt) 'call_list' containing original function call 'calibrate_thresholds_inputs' list containing inputs original function call proportion positive trials measure type error null setting, measure power alternative setting.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/calibrate_thresholds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrate according to posterior probability threshold and predictive\r\nprobability threshold with interim futility monitoring — calibrate_thresholds","text":"","code":"# One-sample case set.seed(123)  calibrate_thresholds(   p_null = 0.1,    p_alt = 0.4,   n = seq(5, 15, 5),    N = 15,   pp_threshold = c(0.85, 0.9),   ppp_threshold = c(0.1, 0.2),   S = 10,    nsim = 10   ) #> Joining with `by = join_by(sim_num, pp_threshold, ppp_threshold)` #> # A tibble: 4 × 8 #>   pp_threshold ppp_threshold mean_n1_n…¹ prop_…² prop_…³ mean_…⁴ prop_…⁵ prop_…⁶ #>          <dbl>         <dbl>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #> 1         0.85           0.1        13.5     0.1     0.2      15     1         0 #> 2         0.85           0.2        10.5     0.1     0.6      15     0.9       0 #> 3         0.9            0.1        12.5     0       0.3      15     0.5       0 #> 4         0.9            0.2        11       0.1     0.5      15     0.6       0 #> # … with abbreviated variable names ¹​mean_n1_null, ²​prop_pos_null, #> #   ³​prop_stopped_null, ⁴​mean_n1_alt, ⁵​prop_pos_alt, ⁶​prop_stopped_alt  # Two-sample case set.seed(456)  calibrate_thresholds(   p_null = c(0.1, 0.1),    p_alt = c(0.1, 0.5),   n = cbind(seq(5, 15, 5), seq(5, 15, 5)),    N = c(15, 15),   pp_threshold = c(0.8, 0.85),   ppp_threshold = c(0.2, 0.3),   delta = 0,   S = 10,    nsim = 10   ) #> Joining with `by = join_by(sim_num, pp_threshold, ppp_threshold)` #> # A tibble: 4 × 10 #>   pp_threshold ppp_thr…¹ mean_…² mean_…³ prop_…⁴ prop_…⁵ mean_…⁶ mean_…⁷ prop_…⁸ #>          <dbl>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #> 1         0.8        0.2     9       9         0     0.9      15      15       1 #> 2         0.8        0.3     7.5     7.5       0     0.9      15      15       1 #> 3         0.85       0.2     8.5     8.5       0     0.8      15      15       1 #> 4         0.85       0.3     8       8         0     0.9      15      15       1 #> # … with 1 more variable: prop_stopped_alt <dbl>, and abbreviated variable #> #   names ¹​ppp_threshold, ²​mean_n0_null, ³​mean_n1_null, ⁴​prop_pos_null, #> #   ⁵​prop_stopped_null, ⁶​mean_n0_alt, ⁷​mean_n1_alt, ⁸​prop_pos_alt"},{"path":"https://www.emilyzabor.com/ppseq/reference/eval_thresh.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate a single dataset for a single pp_threshold and ppp_threshold\r\ncombination — eval_thresh","title":"Evaluate a single dataset for a single pp_threshold and ppp_threshold\r\ncombination — eval_thresh","text":"Helper function calibrate_thresholds() function evaluates single combination pp_threshold ppp_threshold single dataset","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/eval_thresh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate a single dataset for a single pp_threshold and ppp_threshold\r\ncombination — eval_thresh","text":"","code":"eval_thresh(   data,   pp_threshold,   ppp_threshold,   p0,   N,   direction = \"greater\",   delta = NULL,   monitoring = \"futility\",   prior = c(0.5, 0.5),   S = 5000 )"},{"path":"https://www.emilyzabor.com/ppseq/reference/eval_thresh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate a single dataset for a single pp_threshold and ppp_threshold\r\ncombination — eval_thresh","text":"data name dataset pp_threshold posterior probability threshold interest ppp_threshold posterior probability threshold interest futility monitoring p0 target value compare one-sample case. Set NULL two-sample case. N total planned sample size end trial, c(N0, N1) two-sample case; integer total planned sample size end trial N one-sample case direction \"greater\" (default) interest P(p1 > p0) \"less\" interest P(p1 < p0) two-sample case. one-sample case, \"greater\" interest P(p > p0) \"less\" interest P(p < p0). delta clinically meaningful difference groups. Typically 0 two-sample case. NULL one-sample case (default). monitoring type interim monitoring performed. One \"futility\" \"efficacy\". Default \"futility\". prior hyperparameters prior beta distribution. Beta(0.5, 0.5) default S number samples, default 5000","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/eval_thresh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate a single dataset for a single pp_threshold and ppp_threshold\r\ncombination — eval_thresh","text":"Returns tibble total sample size end trial, number responses observed end trial, pp_threshold considered, ppp_threshold considered, observed predictive probability generated calc_predictive(), indicator whether trial positive end","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/one_sample_cal_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Output from a one-sample call to calibrate_thresholds — one_sample_cal_tbl","title":"Output from a one-sample call to calibrate_thresholds — one_sample_cal_tbl","text":".rda file contains output one-sample call calibrate_thresholds(). See vignette titled \"One-sample expansion cohort\" description input parameters used, run one_sample_cal_tbl$inputs see list original function inputs. use testing functions vignettes.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/one_sample_cal_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output from a one-sample call to calibrate_thresholds — one_sample_cal_tbl","text":"","code":"data(one_sample_cal_tbl)"},{"path":"https://www.emilyzabor.com/ppseq/reference/one_sample_cal_tbl.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Output from a one-sample call to calibrate_thresholds — one_sample_cal_tbl","text":"list containing tibble 'res_summary' containing posterior probability threshold (pp_threshold); predictive probability threshold (ppp_threshold); mean sample size null (mean_n1_null) alternative (mean_n1_alt) response rates; proportion positive trials null (prop_pos_null) alternative (prop_pos_alt) response rates; proportion trials stopped null (prop_stopped_null) alternative (prop_stopped_alt) response rates 'call_list' containing original function call 'inputs' list containing inputs original function call","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/one_sample_decision_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Output from a one-sample call to calc_decision_rules — one_sample_decision_tbl","title":"Output from a one-sample call to calc_decision_rules — one_sample_decision_tbl","text":".rda file contains output one-sample call calc_decision_rules(). See vignette titled \"One-sample expansion cohort\" description input parameters used.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/one_sample_decision_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output from a one-sample call to calc_decision_rules — one_sample_decision_tbl","text":"","code":"data(one_sample_decision_tbl)"},{"path":"https://www.emilyzabor.com/ppseq/reference/one_sample_decision_tbl.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Output from a one-sample call to calc_decision_rules — one_sample_decision_tbl","text":"tibble containing n, number patients enrolled futility monitoring point; r, number responses stop trial given look number observed responses <=r, end trial treatment considered promising number observed responses >r; ppp, predictive probability given look","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/optimize_design.calibrate_thresholds.html","id":null,"dir":"Reference","previous_headings":"","what":"Custom optimization method for calibrate_thresholds objects — optimize_design.calibrate_thresholds","title":"Custom optimization method for calibrate_thresholds objects — optimize_design.calibrate_thresholds","text":"Determines optimal designs based variety criteria. optimal efficiency design one shortest Euclidean distance upper left point plot average sample size null average sample size alternative. optimal accuracy design one shortest Euclidean distance upper left point plot type error power.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/optimize_design.calibrate_thresholds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Custom optimization method for calibrate_thresholds objects — optimize_design.calibrate_thresholds","text":"","code":"# S3 method for calibrate_thresholds optimize_design(   x,   type1_range = c(0, 1),   minimum_power = 0,   w_type1 = 1,   w_power = 1,   w_Nnull = 1,   w_Nalt = 1,   ... )"},{"path":"https://www.emilyzabor.com/ppseq/reference/optimize_design.calibrate_thresholds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Custom optimization method for calibrate_thresholds objects — optimize_design.calibrate_thresholds","text":"x object class 'calibrate_thresholds', usually returned calibrate_thresholds function type1_range vector specifying minimum maximum acceptable type error. Specify NULL return full range resulting type error. Defaults c(0, 1) return results. minimum_power numeric 0 1 specifying minimum acceptable power. Specify NULL return full range resulting power. Defaults 0 return results. w_type1 user-specified weight type 1 error. Defaults 1 weighting. w_power user-specified weight power. Defaults 1 weighting. w_Nnull user-specified weight average sample size null. Defaults 1 weighting. w_Nalt user-specified weight average sample size alternative. Defaults 1 weighting. ... ignored","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/optimize_design.calibrate_thresholds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Custom optimization method for calibrate_thresholds objects — optimize_design.calibrate_thresholds","text":"list length two containing details optimal efficiency optimal accuracy designs","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/optimize_design.calibrate_thresholds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Custom optimization method for calibrate_thresholds objects — optimize_design.calibrate_thresholds","text":"","code":"# Setting S = 50 and nsim = 50 for speed # In practice you would want a much larger sample and more simulations  # One-sample case set.seed(123)  cal_tbl1 <- calibrate_thresholds(   p_null = 0.1,    p_alt = 0.4,   n = seq(5, 15, 5),    N = 15,   pp_threshold = c(0.85, 0.9),   ppp_threshold = c(0.1, 0.2),   S = 10,    nsim = 10   ) #> Joining with `by = join_by(sim_num, pp_threshold, ppp_threshold)`  optimize_design(cal_tbl1) #> $`Optimal accuracy design:` #> # A tibble: 1 × 6 #>   pp_threshold ppp_threshold `Type I error` Power `Average N under the null` #>          <dbl>         <dbl>          <dbl> <dbl>                      <dbl> #> 1         0.85           0.1            0.1     1                       13.5 #>   `Average N under the alternative` #>                               <dbl> #> 1                                15 #>  #> $`Optimal efficiency design:` #> # A tibble: 1 × 6 #>   pp_threshold ppp_threshold `Type I error` Power `Average N under the null` #>          <dbl>         <dbl>          <dbl> <dbl>                      <dbl> #> 1         0.85           0.2            0.1   0.9                       10.5 #>   `Average N under the alternative` #>                               <dbl> #> 1                                15 #>    # Two-sample case set.seed(456)  cal_tbl2 <- calibrate_thresholds(   p_null = c(0.1, 0.1),    p_alt = c(0.1, 0.5),   n = cbind(seq(5, 15, 5), seq(5, 15, 5)),    N = c(15, 15),   pp_threshold = c(0.8, 0.85),   ppp_threshold = c(0.2, 0.3),   delta = 0,   S = 10,    nsim = 10   ) #> Joining with `by = join_by(sim_num, pp_threshold, ppp_threshold)`  optimize_design(cal_tbl2) #> $`Optimal accuracy design:` #> # A tibble: 1 × 6 #>   pp_threshold ppp_threshold `Type I error` Power `Average N under the null` #>          <dbl>         <dbl>          <dbl> <dbl>                      <dbl> #> 1         0.85           0.3              0     1                          8 #>   `Average N under the alternative` #>                               <dbl> #> 1                                15 #>  #> $`Optimal efficiency design:` #> # A tibble: 1 × 6 #>   pp_threshold ppp_threshold `Type I error` Power `Average N under the null` #>          <dbl>         <dbl>          <dbl> <dbl>                      <dbl> #> 1          0.8           0.3              0     1                        7.5 #>   `Average N under the alternative` #>                               <dbl> #> 1                                15 #>"},{"path":"https://www.emilyzabor.com/ppseq/reference/optimize_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to setup usage of optimize_design.calibrate_thresholds — optimize_design","title":"Function to setup usage of optimize_design.calibrate_thresholds — optimize_design","text":"Function setup usage optimize_design.calibrate_thresholds","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/optimize_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to setup usage of optimize_design.calibrate_thresholds — optimize_design","text":"","code":"optimize_design(x, type1_range = c(0, 1), minimum_power = 0, ...)"},{"path":"https://www.emilyzabor.com/ppseq/reference/optimize_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to setup usage of optimize_design.calibrate_thresholds — optimize_design","text":"x object class 'calibrate_thresholds', usually returned calibrate_thresholds function type1_range vector specifying minimum maximum acceptable type error. Specify NULL return full range resulting type error. Defaults c(0, 1) return results. minimum_power numeric 0 1 specifying minimum acceptable power. Specify NULL return full range resulting power. Defaults 0 return results. ... ignored","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/plot.calc_decision_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for calc_decision_rules objects — plot.calc_decision_rules","title":"Plot method for calc_decision_rules objects — plot.calc_decision_rules","text":"Returns plot decision rules results calc_decision_rules can interactively show stop proceed various interim analyses","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/plot.calc_decision_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for calc_decision_rules objects — plot.calc_decision_rules","text":"","code":"# S3 method for calc_decision_rules plot(x, plotly = TRUE, ...)"},{"path":"https://www.emilyzabor.com/ppseq/reference/plot.calc_decision_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for calc_decision_rules objects — plot.calc_decision_rules","text":"x object class 'calc_decision_rules', usually returned calc_decision_rules function plotly plot rendered plotly? (Default TRUE) ... unused","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/plot.calc_decision_rules.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for calc_decision_rules objects — plot.calc_decision_rules","text":"one-sample case, heatmap plot number enrolled x-axis number responses y-axis. two-sample case, grid heatmap plots. plot combination number enrolled far experimental control arms. x-axis number responses control arm y-axis number responses experimental arm. Green indicates combinations trial proceed red indicates combinations trial stop.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/plot.calc_decision_rules.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for calc_decision_rules objects — plot.calc_decision_rules","text":"","code":"set.seed(123)  # Two-sample case dec_tbl <- calc_decision_rules(   n = cbind(seq(5, 15, 5), seq(5, 15, 5)),   N = c(15, 15),   theta = 0.86,   ppp = 0.2,   p0 = NULL,   direction = \"greater\",   delta = 0,   S = 50 )  plot(dec_tbl, plotly = FALSE) #> Joining with `by = join_by(n0, n1, r0, r1)`"},{"path":"https://www.emilyzabor.com/ppseq/reference/plot.calibrate_thresholds.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for calibrate_thresholds objects — plot.calibrate_thresholds","title":"Plot method for calibrate_thresholds objects — plot.calibrate_thresholds","text":"Returns two interactive plotly plots (plotly=TRUE) two static ggplot2 plots (plotly=FALSE) compare results various designs generated call calibrate_thresholds based various criteria, assist selecting optimal design.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/plot.calibrate_thresholds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for calibrate_thresholds objects — plot.calibrate_thresholds","text":"","code":"# S3 method for calibrate_thresholds plot(x, type1_range = c(0, 1), minimum_power = 0, plotly = FALSE, ...)"},{"path":"https://www.emilyzabor.com/ppseq/reference/plot.calibrate_thresholds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for calibrate_thresholds objects — plot.calibrate_thresholds","text":"x object class 'calibrate_thresholds', usually returned calibrate_thresholds function type1_range vector specifying minimum maximum acceptable type error. Specify c(0, 1) return full range resulting type error. Defaults c(0, 1) minimum_power numeric 0 1 specifying minimum acceptable power. Specify 0 return full range resulting power. Defaults 0. plotly logical indicator whether want plots returned interactive plotly plots non-interactive ggplots. Defaults FALSE. ... unused","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/plot.calibrate_thresholds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for calibrate_thresholds objects — plot.calibrate_thresholds","text":"Plots average sample size null average sample size alternative, type error power designs meeting specified type1_range minimum_power","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/plot.calibrate_thresholds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for calibrate_thresholds objects — plot.calibrate_thresholds","text":"","code":"# Setting S = 50 and nsim = 50 for speed # In practice you would want a much larger sample and more simulations  set.seed(123)  # One-sample case cal_tbl1 <- calibrate_thresholds(   p_null = 0.1,   p_alt = 0.4,   n = seq(5, 15, 5),   N = 15,   pp_threshold = c(0.85, 0.9),   ppp_threshold = c(0.1, 0.2),   S = 10,   nsim = 10   ) #> Joining with `by = join_by(sim_num, pp_threshold, ppp_threshold)`  plot(cal_tbl1, type1_range = c(0.01, 0.2), minimum_power = 0.7)"},{"path":"https://www.emilyzabor.com/ppseq/reference/ppseq-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ppseq: Design Clinical Trials using Sequential Predictive Probability Monitoring — ppseq-package","title":"ppseq: Design Clinical Trials using Sequential Predictive Probability Monitoring — ppseq-package","text":"Functions available calibrate designs range posterior predictive thresholds, plot various design options, obtain operating characteristics optimal accuracy optimal efficiency designs.","code":""},{"path":[]},{"path":"https://www.emilyzabor.com/ppseq/reference/ppseq-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ppseq: Design Clinical Trials using Sequential Predictive Probability Monitoring — ppseq-package","text":"Maintainer: Emily C. Zabor zabore2@ccf.org (ORCID) Authors: Brian P. Hobbs Michael J. Kane michael.kane@yale.edu (ORCID)","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/print.calibrate_thresholds.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for calibrate_thresholds objects — print.calibrate_thresholds","title":"Print method for calibrate_thresholds objects — print.calibrate_thresholds","text":"default prints res_summary table object class 'calibrate_thresholds'. table can limited range type 1 error minimum value power using arguments 'type1_range' 'minimum_power' respectively.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/print.calibrate_thresholds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for calibrate_thresholds objects — print.calibrate_thresholds","text":"","code":"# S3 method for calibrate_thresholds print(x, type1_range = c(0, 1), minimum_power = 0, ...)"},{"path":"https://www.emilyzabor.com/ppseq/reference/print.calibrate_thresholds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for calibrate_thresholds objects — print.calibrate_thresholds","text":"x object class 'calibrate_thresholds', usually returned calibrate_thresholds function type1_range vector specifying minimum maximum acceptable type error. Specify c(0, 1) return full range resulting type error. Defaults c(0, 1) minimum_power numeric 0 1 specifying minimum acceptable power. Specify 0 return full range resulting power. Defaults 0. ... ignored","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/print.calibrate_thresholds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for calibrate_thresholds objects — print.calibrate_thresholds","text":"Returns tibble","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/print.calibrate_thresholds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for calibrate_thresholds objects — print.calibrate_thresholds","text":"","code":"set.seed(123)  cal_tbl1 <- calibrate_thresholds(   p_null = 0.1,   p_alt = 0.4,   n = seq(5, 15, 5),   N = 15,   pp_threshold = c(0.85, 0.9),   ppp_threshold = c(0.1, 0.2),   S = 10,   nsim = 10   ) #> Joining with `by = join_by(sim_num, pp_threshold, ppp_threshold)`  print(cal_tbl1) #> # A tibble: 4 × 8 #>   pp_threshold ppp_threshold mean_n1_null prop_pos_null prop_stopped_null #>          <dbl>         <dbl>        <dbl>         <dbl>             <dbl> #> 1         0.85           0.1         13.5           0.1               0.2 #> 2         0.85           0.2         10.5           0.1               0.6 #> 3         0.9            0.1         12.5           0                 0.3 #> 4         0.9            0.2         11             0.1               0.5 #>   mean_n1_alt prop_pos_alt prop_stopped_alt #>         <dbl>        <dbl>            <dbl> #> 1          15          1                  0 #> 2          15          0.9                0 #> 3          15          0.5                0 #> 4          15          0.6                0 print(cal_tbl1, type1_range = c(0.05, 0.1), minimum_power = 0.9) #> # A tibble: 2 × 8 #>   pp_threshold ppp_threshold mean_n1_null prop_pos_null prop_stopped_null #>          <dbl>         <dbl>        <dbl>         <dbl>             <dbl> #> 1         0.85           0.1         13.5           0.1               0.2 #> 2         0.85           0.2         10.5           0.1               0.6 #>   mean_n1_alt prop_pos_alt prop_stopped_alt #>         <dbl>        <dbl>            <dbl> #> 1          15          1                  0 #> 2          15          0.9                0"},{"path":"https://www.emilyzabor.com/ppseq/reference/sim_dat1.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a single dataset based on the response probability(ies), the total\r\nsample size(s), and the interim look schedule(s) — sim_dat1","title":"Simulate a single dataset based on the response probability(ies), the total\r\nsample size(s), and the interim look schedule(s) — sim_dat1","text":"Helper function calibrate_thresholds() function generates single dataset n response count look based response probability(ies)","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/sim_dat1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a single dataset based on the response probability(ies), the total\r\nsample size(s), and the interim look schedule(s) — sim_dat1","text":"","code":"sim_dat1(p, n)"},{"path":"https://www.emilyzabor.com/ppseq/reference/sim_dat1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a single dataset based on the response probability(ies), the total\r\nsample size(s), and the interim look schedule(s) — sim_dat1","text":"p vector length two containing probability event standard care experimental arm c(p0, p1) two-sample case; integer event probability one-sample case n matrix containing total number patients accrued far interim look standard care (column 1) experimental (column 2) arms two-sample case; vector sample size accrued far interim look one-sample case. last value equal total sample size end trial. single look done end trial, can vector specifying total sample size c(N0, N1) two-sample case integer specifying total sample size N one-sample case","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/sim_dat1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a single dataset based on the response probability(ies), the total\r\nsample size(s), and the interim look schedule(s) — sim_dat1","text":"Returns tibble n0, n1, y0, y1 two-sample case tibble n1 y1 one-sample case","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/sim_single_trial.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a single trial with posterior probability monitoring — sim_single_trial","title":"Simulate a single trial with posterior probability monitoring — sim_single_trial","text":"function meant used context clinical trial binary endpoint. goal simulate event counts binomial distribution based number patients accrued interim look, calculate posterior predictive probability success (futility) end trial, given data available interim analysis.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/sim_single_trial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a single trial with posterior probability monitoring — sim_single_trial","text":"","code":"sim_single_trial(   p,   n,   p0,   N,   direction = \"greater\",   delta = NULL,   prior = c(0.5, 0.5),   S = 5000,   theta = 0.95 )"},{"path":"https://www.emilyzabor.com/ppseq/reference/sim_single_trial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a single trial with posterior probability monitoring — sim_single_trial","text":"p vector length two containing probability event standard care experimental arm c(p0, p1) two-sample case; integer event probability one-sample case n matrix containing total number patients accrued far interim look standard care (column 1) experimental (column 2) arms two-sample case; vector sample size accrued far interim look one-sample case. last value equal total sample size end trial. single look done end trial, can vector specifying total sample size c(N0, N1) two-sample case integer specifying total sample size N one-sample case. p0 target value compare one-sample case N total planned sample size end trial, c(N0, N1) two-sample case; integer total planned sample size end trial N one-sample case direction \"greater\" (default) interest P(p1 > p0) \"less\" interest P(p1 < p0) two-sample case. one-sample case, \"greater\" interest P(p > p0) \"less\" interest P(p < p0). delta clinically meaningful difference groups. Typically 0 two-sample case. NULL one-sample case (default). prior hyperparameters prior beta distribution. Beta(0.5, 0.5) default S number samples, default 5000 theta target posterior probability. e.g. Efficacy decision P(p1 > p0) > theta two-sample case greater direction. Default 0.95. Can vector interest selecting among variety thresholds.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/sim_single_trial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a single trial with posterior probability monitoring — sim_single_trial","text":"Returns tibble pp_threshold (.e. theta, target posterior probability), number responses, sample size, posterior probability, posterior predictive probability look","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/sim_single_trial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate a single trial with posterior probability monitoring — sim_single_trial","text":"","code":"set.seed(123)  # Setting S = 100 for speed, in practice you would want a much larger sample  # One-sample case sim_single_trial(   p = 0.3,    n = c(5, 10),     p0 = 0.1,    N = 25,    S = 100   ) #> # A tibble: 2 × 5 #>   pp_threshold    y1    n1    pp   ppp #>          <dbl> <int> <dbl> <dbl> <dbl> #> 1         0.95     1     5  0.84  0.54 #> 2         0.95     3    10  0.99  0.8   # Two-sample case  sim_single_trial(   p = c(0.1, 0.3),    n = cbind(c(5, 10), c(5, 10)),    p0 = NULL,    N = c(50, 50),    delta = 0,    S = 100   ) #> # A tibble: 2 × 7 #>   pp_threshold    y0    y1    n0    n1    pp   ppp #>          <dbl> <int> <int> <dbl> <dbl> <dbl> <dbl> #> 1         0.95     1     1     5     5  0.4   0.26 #> 2         0.95     1     2    10    10  0.73  0.38"},{"path":"https://www.emilyzabor.com/ppseq/reference/two_sample_cal_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Output from a two-sample call to calibrate_thresholds — two_sample_cal_tbl","title":"Output from a two-sample call to calibrate_thresholds — two_sample_cal_tbl","text":".rda file contains output two-sample call calibrate_thresholds(). See vignette titled \"Two-sample randomized trial\" description input parameters used, run two_sample_cal_tbl$inputs see list original function inputs. use testing functions vignettes.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/two_sample_cal_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output from a two-sample call to calibrate_thresholds — two_sample_cal_tbl","text":"","code":"data(two_sample_cal_tbl)"},{"path":"https://www.emilyzabor.com/ppseq/reference/two_sample_cal_tbl.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Output from a two-sample call to calibrate_thresholds — two_sample_cal_tbl","text":"list containing tibble 'res_summary' containing posterior probability threshold (pp_threshold); predictive probability threshold (ppp_threshold); mean sample size null (mean_n0_null mean_n1_null) alternative (mean_n0_alt mean_n1_alt) response rates; proportion positive trials null (prop_pos_null) alternative (prop_pos_alt) response rates; proportion trials stopped null (prop_stopped_null) alternative (prop_stopped_alt) response rates. 'call_list' containing original function call 'inputs' list containing inputs original function call","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/two_sample_decision_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Output from a two-sample call to calc_decision_rules — two_sample_decision_tbl","title":"Output from a two-sample call to calc_decision_rules — two_sample_decision_tbl","text":".rda file contains output two-sample call calc_decision_rules(). See vignette titled \"Two-sample randomized trail\" description input parameters used.","code":""},{"path":"https://www.emilyzabor.com/ppseq/reference/two_sample_decision_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output from a two-sample call to calc_decision_rules — two_sample_decision_tbl","text":"","code":"data(two_sample_decision_tbl)"},{"path":"https://www.emilyzabor.com/ppseq/reference/two_sample_decision_tbl.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Output from a two-sample call to calc_decision_rules — two_sample_decision_tbl","text":"tibble containing n, number patients enrolled futility monitoring point; r, number responses stop trial given look number observed responses <=r, end trial treatment considered promising number observed responses >r; ppp, predictive probability given look","code":""},{"path":"https://www.emilyzabor.com/ppseq/news/index.html","id":"ppseq-022","dir":"Changelog","previous_headings":"","what":"ppseq 0.2.2","title":"ppseq 0.2.2","text":"updated two-sample vignette results (Closed Issue #23) corrected code bug calc_decision_rules() (Closed Issue #21) corrected code bug calibrate_thresholds() (Closed Issue #19) replaced purrr::cross_df() (deprecated) tidyr::expand_grid()","code":""},{"path":"https://www.emilyzabor.com/ppseq/news/index.html","id":"ppseq-021","dir":"Changelog","previous_headings":"","what":"ppseq 0.2.1","title":"ppseq 0.2.1","text":"updated datasets use different predictive thresholds correspondingly updated vignettes","code":""},{"path":"https://www.emilyzabor.com/ppseq/news/index.html","id":"ppseq-020","dir":"Changelog","previous_headings":"","what":"ppseq 0.2.0","title":"ppseq 0.2.0","text":"CRAN release: 2022-08-08 added weighting options optimize_design() (Closed Issue #7) added informative messaging results returned optimize_design() (Closed Issue #14) upgraded package website bootstrap 5 changed styling added two-sample randomized trial vignette added calc_next() function calculate probability response next patient (Closed Issue #2) fixed bug default arguments optimize_design() (Closed Issue #12) added efficacy monitoring option, default still futility monitoring (Closed Issue #3)","code":""},{"path":"https://www.emilyzabor.com/ppseq/news/index.html","id":"ppseq-012","dir":"Changelog","previous_headings":"","what":"ppseq 0.1.2","title":"ppseq 0.1.2","text":"Updating examples run without \\donttest{} minor documentation changes","code":""},{"path":"https://www.emilyzabor.com/ppseq/news/index.html","id":"ppseq-011","dir":"Changelog","previous_headings":"","what":"ppseq 0.1.1","title":"ppseq 0.1.1","text":"CRAN release: 2021-09-09 Updating included example data files Changes data files reflected vignette","code":""},{"path":"https://www.emilyzabor.com/ppseq/news/index.html","id":"ppseq-010","dir":"Changelog","previous_headings":"","what":"ppseq 0.1.0","title":"ppseq 0.1.0","text":"Initial package release","code":""}]
